#!/bin/bash

#SBATCH --nodes 4
#SBATCH --ntasks-per-node 1
#SBATCH --partition veryshort
#SBATCH --reservation=COSC026662
#SBATCH --account=COSC026662
#SBATCH --job-name MPI
#SBATCH --time 00:15:00
#SBATCH --output OUT.o
#SBATCH --exclude=compute104,compute105,compute127,compute216,compute300
#SBATCH --exclusive

# This time, asking for 2 nodes, with 1 task per node

# Use Intel MPI (make sure you compile with the same module and 'mpiicc')
module load languages/intel/2020-u4


# Print some information about the job
echo "Running on host $(hostname)"
echo "Time is $(date)"
echo "Directory is $(pwd)"
echo "Slurm job ID is $SLURM_JOB_ID"
echo
echo "This job runs on the following machines:"
echo "$SLURM_JOB_NODELIST" | uniq
echo


# Enable using `srun` with Intel MPI
# export I_MPI_PMI_LIBRARY=/usr/lib64/libpmi.so

# Run the parallel MPI executable
echo "Running send_recv"
srun --mpi=pmi2 ./send_recv

# echo
# echo "Running simple-pingpong"
# srun --mpi=pmi2 ./simple-pingpong

# echo
# echo "Running deadlock"
# srun --mpi=pmi2 ./deadlock 1